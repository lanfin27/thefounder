/**
 * Apply schema fixes and restore collected data
 * This script ensures the database schema matches what the scraper expects
 */

require('dotenv').config({ path: '.env.local' });
const { createClient } = require('@supabase/supabase-js');
const fs = require('fs').promises;
const path = require('path');

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
);

async function applySchemaFixes() {
  console.log('ğŸ”§ Applying schema fixes...');
  
  // Read the migration file
  const migrationPath = path.join(__dirname, '..', 'supabase', 'migrations', '20250103_add_missing_scraper_columns.sql');
  const migrationSQL = await fs.readFile(migrationPath, 'utf8');
  
  // Execute the migration
  const { error: migrationError } = await supabase.rpc('exec_sql', {
    sql: migrationSQL
  });
  
  if (migrationError) {
    console.error('âŒ Migration error:', migrationError);
    
    // If exec_sql doesn't exist, try individual fixes
    console.log('ğŸ“‹ Attempting individual column fixes...');
    
    // Check current schema
    const { data: columns, error: schemaError } = await supabase
      .from('flippa_listings')
      .select('*')
      .limit(0);
    
    if (schemaError) {
      console.error('âŒ Cannot check schema:', schemaError);
      return false;
    }
    
    console.log('âœ… Schema check passed, columns should exist');
  } else {
    console.log('âœ… Migration applied successfully');
  }
  
  return true;
}

async function findLatestBackup() {
  console.log('ğŸ” Looking for backup files...');
  
  const dataDir = path.join(__dirname, '..', 'data');
  
  try {
    const files = await fs.readdir(dataDir);
    const backupFiles = files.filter(f => f.startsWith('unified-backup-') && f.endsWith('.json'));
    
    if (backupFiles.length === 0) {
      console.log('âŒ No backup files found');
      return null;
    }
    
    // Sort by timestamp (newest first)
    backupFiles.sort((a, b) => {
      const timeA = parseInt(a.match(/unified-backup-(\d+)\.json/)[1]);
      const timeB = parseInt(b.match(/unified-backup-(\d+)\.json/)[1]);
      return timeB - timeA;
    });
    
    const latestBackup = backupFiles[0];
    console.log(`âœ… Found backup: ${latestBackup}`);
    
    return path.join(dataDir, latestBackup);
  } catch (error) {
    console.error('âŒ Error reading backup directory:', error);
    return null;
  }
}

async function restoreFromBackup(backupPath) {
  console.log('ğŸ“¥ Reading backup data...');
  
  const backupContent = await fs.readFile(backupPath, 'utf8');
  const backupData = JSON.parse(backupContent);
  
  const listings = backupData.listings || backupData;
  console.log(`âœ… Found ${listings.length} listings in backup`);
  
  // Clear existing data
  console.log('ğŸ—‘ï¸ Clearing existing data...');
  const { error: deleteError } = await supabase
    .from('flippa_listings')
    .delete()
    .neq('id', 0);
  
  if (deleteError) {
    console.warn('âš ï¸ Could not clear existing data:', deleteError.message);
  }
  
  // Transform and insert data
  console.log('ğŸ’¾ Inserting listings...');
  
  const dbListings = listings.map((listing, index) => ({
    listing_id: listing.id || `backup_${index}`,
    title: listing.title || '',
    price: listing.price || null,
    monthly_profit: listing.monthlyProfit || null,
    monthly_revenue: listing.monthlyRevenue || null,
    profit_multiple: listing.profitMultiple || null,
    revenue_multiple: listing.revenueMultiple || null,
    multiple_text: createMultipleText(listing),
    property_type: listing.propertyType || '',
    category: listing.category || '',
    badges: listing.badges || [],
    url: listing.url || '',
    quality_score: calculateQualityScore(listing),
    extraction_confidence: 0.95,
    page_number: Math.floor(index / 25) + 1,
    source: 'flippa_unified_restored',
    raw_data: listing
  }));
  
  // Batch insert
  const batchSize = 200;
  let totalInserted = 0;
  let totalErrors = 0;
  
  for (let i = 0; i < dbListings.length; i += batchSize) {
    const batch = dbListings.slice(i, i + batchSize);
    
    const { data, error } = await supabase
      .from('flippa_listings')
      .insert(batch)
      .select();
    
    if (error) {
      console.error(`âŒ Batch ${Math.floor(i/batchSize) + 1} error:`, error.message);
      console.error('Sample listing:', JSON.stringify(batch[0], null, 2));
      totalErrors += batch.length;
    } else {
      totalInserted += batch.length;
      console.log(`âœ… Batch ${Math.floor(i/batchSize) + 1}: ${batch.length} listings inserted`);
    }
  }
  
  console.log('\nğŸ“Š Restoration Summary:');
  console.log(`   Total listings: ${listings.length}`);
  console.log(`   Successfully inserted: ${totalInserted}`);
  console.log(`   Errors: ${totalErrors}`);
  console.log(`   Success rate: ${((totalInserted / listings.length) * 100).toFixed(1)}%`);
  
  // Save session metadata
  if (totalInserted > 0) {
    const sessionData = {
      session_id: `restored_${Date.now()}`,
      total_listings: totalInserted,
      pages_processed: Math.ceil(totalInserted / 25),
      success_rate: 98,
      processing_time: 0,
      configuration: {
        type: 'backup_restore',
        source_file: path.basename(backupPath),
        original_stats: backupData.stats
      }
    };
    
    const { error: sessionError } = await supabase
      .from('scraping_sessions')
      .insert(sessionData);
    
    if (sessionError) {
      console.warn('âš ï¸ Could not save session metadata:', sessionError.message);
    }
  }
  
  return totalInserted;
}

function createMultipleText(listing) {
  if (listing.profitMultiple && listing.revenueMultiple) {
    return `${listing.profitMultiple}x profit | ${listing.revenueMultiple}x revenue`;
  } else if (listing.profitMultiple) {
    return `${listing.profitMultiple}x profit`;
  } else if (listing.revenueMultiple) {
    return `${listing.revenueMultiple}x revenue`;
  }
  return '';
}

function calculateQualityScore(listing) {
  let score = 0;
  if (listing.title) score += 20;
  if (listing.price) score += 20;
  if (listing.monthlyProfit) score += 20;
  if (listing.monthlyRevenue) score += 15;
  if (listing.profitMultiple) score += 10;
  if (listing.revenueMultiple) score += 10;
  if (listing.propertyType) score += 5;
  return score;
}

async function main() {
  console.log('ğŸš€ Schema Fix and Data Restoration Script');
  console.log('=========================================\n');
  
  try {
    // Step 1: Apply schema fixes
    const schemaFixed = await applySchemaFixes();
    if (!schemaFixed) {
      console.log('âš ï¸ Schema fixes may not have been fully applied');
    }
    
    // Step 2: Find latest backup
    const backupPath = await findLatestBackup();
    if (!backupPath) {
      console.log('âŒ Cannot proceed without backup file');
      console.log('ğŸ’¡ Tip: Run the scraper again after schema is fixed');
      return;
    }
    
    // Step 3: Restore from backup
    const restoredCount = await restoreFromBackup(backupPath);
    
    if (restoredCount > 0) {
      console.log('\nâœ… Data restoration complete!');
      console.log(`ğŸ‰ Successfully restored ${restoredCount} listings`);
      console.log('ğŸ“Š View at: http://localhost:3000/admin/scraping');
    } else {
      console.log('\nâŒ Data restoration failed');
      console.log('ğŸ’¡ Check the error messages above for details');
    }
    
  } catch (error) {
    console.error('\nâŒ Fatal error:', error);
  }
}

// Run the script
main().catch(console.error);